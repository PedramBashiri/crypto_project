{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77c88d616d9df758663d82400eb570ef43ee619e"
   },
   "source": [
    "Objective:\n",
    "To use Granger Casuality approach to show how sentiments affect the stock prices.\n",
    "About Granger Casuality:\n",
    "1. According to wiki:\n",
    "The Granger causality test is a statistical hypothesis test for determining whether one time series is useful in forecasting another, first proposed in 1969. Ordinarily, regressions reflect \"mere\" correlations, but Clive Granger argued that causality in economics could be tested for by measuring the ability to predict the future values of a time series using prior values of another time series. Since the question of \"true causality\" is deeply philosophical, and because of the post hoc ergo propter hoc fallacy of assuming that one thing preceding another can be used as a proof of causation, econometricians assert that the Granger test finds only \"predictive causality\".\n",
    "\n",
    "Intuitively, granger casuality can be used here to show how sentiments affect the stock market prices. \n",
    "\n",
    "How to determine it?\n",
    "The general observation is that the stock prices are observed to drop down after the sentiment is given. The drop value should be calculated after and before the sentiment is released. The drops should be converted to standard zscore before using for granger casualty tests.\n",
    "I have used a particular asset to make observations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/pbashiri/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kaggle.competitions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5413a6238280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkaggle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompetitions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtwosigmanews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kaggle.competitions'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "from kaggle.competitions import twosigmanews\n",
    "from scipy.stats import zscore\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "# Get 2Sigma environment\n",
    "env = twosigmanews.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Get the data\n",
    "mt_df, nt_df = env.get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f7cb0ca3fc0ffd6e7f04ea6e19fd5cd138cc530"
   },
   "source": [
    "We will try and get the correlation between market data and sentiments. We will consider a particular asset to determine it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f06ad8a9e098fab917b274587486dccac3d65ffa"
   },
   "outputs": [],
   "source": [
    "mt_df['time'] = pd.to_datetime(mt_df['time'])\n",
    "nt_df['time'] = pd.to_datetime(nt_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b9a4e92e5be72a6b94ac68feb2ceb39b541028c"
   },
   "outputs": [],
   "source": [
    "mt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abb130af15c1f0048cecf35bf72dee334ae1bd55"
   },
   "outputs": [],
   "source": [
    "nt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "5e6196cc5fcda82c1f8bbb3f8e69fdde0985ffcc"
   },
   "outputs": [],
   "source": [
    "#understanding the correlation between sentiments and open values for a particular asset so that we can try and generalize it later.\n",
    "asset = 'PetroChina Co Ltd'\n",
    "mt_df_petro_china = mt_df[mt_df['assetName']==asset]\n",
    "nt_df_petro_china = nt_df[nt_df['assetName']==asset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50304d173804bd795fd4aa9de7484c89ae1419aa"
   },
   "outputs": [],
   "source": [
    "def date_(x):\n",
    "    return x.date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0d9981c836bed21e23c3460ff6ba148eb780b60"
   },
   "outputs": [],
   "source": [
    "# consider the open prices and time from market data, consider the sentiments and time from sentiment data\n",
    "mt_df_petro_china = mt_df_petro_china[['time','open']]\n",
    "mt_df_petro_china['date_only'] = mt_df_petro_china['time'].map(date_)\n",
    "mt_df_petro_china['date_only'] = pd.to_datetime(mt_df_petro_china['date_only'])\n",
    "mt_df_petro_china.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58ad96d9146f61da666b292742bf654a3cc24260"
   },
   "outputs": [],
   "source": [
    "nt_df_petro_china = nt_df_petro_china[['time','headline','sentimentNegative','sentimentNeutral','sentimentPositive']]\n",
    "nt_df_petro_china['date_only'] = nt_df_petro_china['time'].map(date_)\n",
    "nt_df_petro_china['date_only'] = pd.to_datetime(nt_df_petro_china['date_only'])\n",
    "nt_df_petro_china['sentiment_max'] = nt_df_petro_china[['sentimentNegative','sentimentNeutral','sentimentPositive']].max(axis=1)\n",
    "nt_df_petro_china.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cac8e5a845432ea035f2cdb94aac4256796d1387"
   },
   "source": [
    "In order to complete this data, we approximated\n",
    "the missing values using a concave function. So,\n",
    "if the open value on a given day is x and the next available\n",
    "data point is y with n days missing in between, we\n",
    "approximate the missing data by estimating the first\n",
    "day after x to be (y+x)/2 and then following the same\n",
    "method recursively till all gaps are filled. This approximation\n",
    "is justified as the stock data usually follows a\n",
    "concave function, unless ofcourse at anomaly points of\n",
    "sudden rise and fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d38f630a7f657a1f2433e45d958bb93788dea87e"
   },
   "outputs": [],
   "source": [
    "date_ranges = pd.date_range(start=mt_df_petro_china['date_only'].min(), end=mt_df_petro_china['date_only'].max())\n",
    "all_dates = mt_df_petro_china['date_only'].values\n",
    "appended_df = pd.DataFrame()\n",
    "for i in range(len(date_ranges)):\n",
    "    d = date_ranges[i]\n",
    "    internal_df = pd.DataFrame(columns=['date','open_value'],index=[i])\n",
    "    df = mt_df_petro_china[mt_df_petro_china['date_only']==pd.to_datetime(d)]\n",
    "    if df.shape[0]!=0:\n",
    "        internal_df['open_value'] = df['open'].values[0]\n",
    "        internal_df['date'] = d\n",
    "        appended_df = appended_df.append(internal_df)\n",
    "    else:\n",
    "        internal_df['open_value'] = 0.0\n",
    "        internal_df['date'] = d\n",
    "        appended_df = appended_df.append(internal_df)\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dda0c443ba3f2d978c661829a3d42efc0a9e7f49"
   },
   "outputs": [],
   "source": [
    "true_open_values = appended_df['open_value'].values\n",
    "modified_ = []\n",
    "for i in range(len(true_open_values)):\n",
    "    open_ = true_open_values[i]\n",
    "    if open_!=0.0:\n",
    "        modified_.append(open_)\n",
    "    else:\n",
    "        i_p_2 = true_open_values[next((k for k, x in enumerate(true_open_values[i-1:]) if x), None)]\n",
    "        modified_.append((true_open_values[i-1]+i_p_2)/2.0)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46d417cdb2eff3400aad7647f7596daf5cffe491"
   },
   "outputs": [],
   "source": [
    "true_open_values = modified_\n",
    "modified_new = []\n",
    "for i in range(len(true_open_values)):\n",
    "    open_ = true_open_values[i]\n",
    "    if open_!=0.0:\n",
    "        modified_new.append(open_)\n",
    "    else:\n",
    "        i_p_2 = true_open_values[next((k for k, x in enumerate(true_open_values[i-1:]) if x), None)]\n",
    "        modified_new.append((true_open_values[i-1]+i_p_2)/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "067e4fd3477c6daa4e2f76117b32335d32f76f6b"
   },
   "outputs": [],
   "source": [
    "appended_df['open_value'] = modified_new\n",
    "appended_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "479f79bfec0d20b26bc8b77a2e52fd99e8be25b0"
   },
   "outputs": [],
   "source": [
    "nt_df_petro_china_avg_sentiments = nt_df_petro_china.groupby('date_only').agg({'sentiment_max':np.mean}).reset_index()\n",
    "nt_df_petro_china_avg_sentiments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5d7365333abd02f183a1a443a26fa53a2453c6b"
   },
   "source": [
    "Get the differencing of the open values before and after sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01f80cfdb682cad5e05602602da417b72eebef30"
   },
   "outputs": [],
   "source": [
    "dates_common = list(set(nt_df_petro_china_avg_sentiments['date_only'].values).intersection(set(appended_df['date'].values)))\n",
    "difference_df = pd.DataFrame()\n",
    "for date in dates_common:\n",
    "    internal_df = pd.DataFrame(columns=['sentiment_value','difference_before_sentiment','difference_after_sentiment'],index=[0])\n",
    "    if date == min(dates_common) or date==max(dates_common):\n",
    "        pass\n",
    "    else:\n",
    "        internal_df['sentiment_value'] = nt_df_petro_china_avg_sentiments[nt_df_petro_china_avg_sentiments['date_only']==date]['sentiment_max'].values[0]\n",
    "        internal_df['difference_before_sentiment'] = appended_df[appended_df['date']==pd.to_datetime(date)]['open_value'].values[0] - appended_df[appended_df['date']==(pd.to_datetime(date)-timedelta(days=1))]['open_value'].values[0]\n",
    "        internal_df['difference_after_sentiment'] = appended_df[appended_df['date']==pd.to_datetime(date)]['open_value'].values[0] - appended_df[appended_df['date']==(pd.to_datetime(date)+timedelta(days=1))]['open_value'].values[0]\n",
    "        internal_df['date'] = date\n",
    "        difference_df = difference_df.append(internal_df)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e60a29d81b7bd0bece800d4e65ed87f82997a963"
   },
   "outputs": [],
   "source": [
    "#get the zscores\n",
    "difference_df['z_score_difference_before_sentiment'] = zscore(difference_df['difference_before_sentiment'])\n",
    "difference_df['z_score_difference_after_sentiment'] = zscore(difference_df['difference_after_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec68dd92ff08bea5d97314f73c3d73a8051392fb"
   },
   "outputs": [],
   "source": [
    "difference_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41ffa3ce3874c14351b19b6dff5ed403e9678c48"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "granger_test_result = grangercausalitytests(difference_df[['sentiment_value','z_score_difference_before_sentiment']].values,maxlag=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f33031c601b358e0309c9f1ea0af314e97b6aca8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d998fc3df63bf0c82576cb005888c6d73c80321e"
   },
   "outputs": [],
   "source": [
    "\n",
    "ts = pd.Series(difference_df['z_score_difference_before_sentiment'].values[:100], index=difference_df['date'].values[:100])\n",
    "ts1 = pd.Series(difference_df['sentiment_value'].values[:100], index=difference_df['date'].values[:100])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "ts1.plot(label='sentiment',color='r')\n",
    "ts.plot(label='z_score_before_sentiment',color='b')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd0afc2fb16358678c2c7f1b198bd727a359366b"
   },
   "source": [
    "Observations:\n",
    "1. “lags”, is the number offset  to look for. For this example, the “lag” is how many days prior a change in trend will impact the opening price.\n",
    "2. For lags=2, p<0.05, hence we can try and build features by offsetting the (prices two days before the sentiment is observed- prices on the day sentiment is observed).\n",
    "3. You can utilize the p-values as follows:\n",
    "If p > .10 → “not significant”\n",
    "If p ≤ .10 → “marginally significant”\n",
    "If p ≤ .05 → “significant”\n",
    "If p ≤ .01 → “highly significant.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38a56d7b644fb41edb5351b8c86383a25edb3c5f"
   },
   "source": [
    "Stay Tuned !! I will be building features based on these observations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
